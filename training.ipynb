{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "319c24ade14b7873a3f936c1569cf8c1853592b8350107cb8f60c9b2a2771b37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# MIBCI-QCNNs: Training\n",
    "\n",
    "This notebook contains all the steps taken to develop an [EEGNet](https://arxiv.org/abs/1611.08024)-based Brain Computer Interface using the [Physionet Motor Movement/Imagery dataset](https://physionet.org/content/eegmmidb/1.0.0/). Firstly, the data is loaded (or downloaded if is not available) and preprocessed according the selected data-reduction settings. Then a 5-fold global model is trained over the preprocessed data, which is used as the starting point for training subject-specific models.\n",
    "\n",
    "## Preporcess the data\n",
    " \n",
    "The data we are using here is the [Physionet Motor Movement/Imagery dataset](https://physionet.org/content/eegmmidb/1.0.0/). It is composed of a 64 Electroencephalograph recordings of 109 subjects that perform up to 4 motor imagery tasks. There are also recording of motor movement that are not interesting under the motor imagery paradigm. To get the data of the dataset we have included the `get_data` function, which is adapted from [this version](https://github.com/MHersche/eegnet-based-embedded-bci/blob/master/get_data.py). If the files haven't been downloaded yet it will download them in the `Dataset`folder. The downsampling factor is set here to be `ds=2` and the other parameters are the default (`T=3`, `Nchans=64` and `Nclasses=4`).\n",
    "\n",
    " > Be aware that the download can take a while"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.get_data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data from runs: [1, 4, 6, 8, 10, 12, 14]\n",
      "Processing subject 001 1/105...Ok\n",
      "Processing subject 002 2/105...Ok\n",
      "Processing subject 003 3/105...Ok\n",
      "Processing subject 004 4/105...Ok\n",
      "Processing subject 005 5/105...Ok\n",
      "Processing subject 006 6/105...Ok\n",
      "Processing subject 007 7/105...Ok\n",
      "Processing subject 008 8/105...Ok\n",
      "Processing subject 009 9/105...Ok\n",
      "Processing subject 010 10/105...Ok\n",
      "Processing subject 011 11/105...Ok\n",
      "Processing subject 012 12/105...Ok\n",
      "Processing subject 013 13/105...Ok\n",
      "Processing subject 014 14/105...Ok\n",
      "Processing subject 015 15/105...Ok\n",
      "Processing subject 016 16/105...Ok\n",
      "Processing subject 017 17/105...Ok\n",
      "Processing subject 018 18/105...Ok\n",
      "Processing subject 019 19/105...Ok\n",
      "Processing subject 020 20/105...Ok\n",
      "Processing subject 021 21/105...Ok\n",
      "Processing subject 022 22/105...Ok\n",
      "Processing subject 023 23/105...Ok\n",
      "Processing subject 024 24/105...Ok\n",
      "Processing subject 025 25/105...Ok\n",
      "Processing subject 026 26/105...Ok\n",
      "Processing subject 027 27/105...Ok\n",
      "Processing subject 028 28/105...Ok\n",
      "Processing subject 029 29/105...Ok\n",
      "Processing subject 030 30/105...Ok\n",
      "Processing subject 031 31/105...Ok\n",
      "Processing subject 032 32/105...Ok\n",
      "Processing subject 033 33/105...Ok\n",
      "Processing subject 034 34/105...Ok\n",
      "Processing subject 035 35/105...Ok\n",
      "Processing subject 036 36/105...Ok\n",
      "Processing subject 037 37/105...Ok\n",
      "Processing subject 038 38/105...Ok\n",
      "Processing subject 039 39/105...Ok\n",
      "Processing subject 040 40/105...Ok\n",
      "Processing subject 041 41/105...Ok\n",
      "Processing subject 042 42/105...Ok\n",
      "Processing subject 043 43/105...Ok\n",
      "Processing subject 044 44/105...Ok\n",
      "Processing subject 045 45/105...Ok\n",
      "Processing subject 046 46/105...Ok\n",
      "Processing subject 047 47/105...Ok\n",
      "Processing subject 048 48/105...Ok\n",
      "Processing subject 049 49/105...Ok\n",
      "Processing subject 050 50/105...Ok\n",
      "Processing subject 051 51/105...Ok\n",
      "Processing subject 052 52/105...Ok\n",
      "Processing subject 053 53/105...Ok\n",
      "Processing subject 054 54/105...Ok\n",
      "Processing subject 055 55/105...Ok\n",
      "Processing subject 056 56/105...Ok\n",
      "Processing subject 057 57/105...Ok\n",
      "Processing subject 058 58/105...Ok\n",
      "Processing subject 059 59/105...Ok\n",
      "Processing subject 060 60/105...Ok\n",
      "Processing subject 061 61/105...Ok\n",
      "Processing subject 062 62/105...Ok\n",
      "Processing subject 063 63/105...Ok\n",
      "Processing subject 064 64/105...Ok\n",
      "Processing subject 065 65/105...Ok\n",
      "Processing subject 066 66/105...Ok\n",
      "Processing subject 067 67/105...Ok\n",
      "Processing subject 068 68/105...Ok\n",
      "Processing subject 069 69/105...Ok\n",
      "Processing subject 070 70/105...Ok\n",
      "Processing subject 071 71/105...Ok\n",
      "Processing subject 072 72/105...Ok\n",
      "Processing subject 073 73/105...Ok\n",
      "Processing subject 074 74/105...Ok\n",
      "Processing subject 075 75/105...Ok\n",
      "Processing subject 076 76/105...Ok\n",
      "Processing subject 077 77/105...Ok\n",
      "Processing subject 078 78/105...Ok\n",
      "Processing subject 079 79/105...Ok\n",
      "Processing subject 080 80/105...Ok\n",
      "Processing subject 081 81/105...Ok\n",
      "Processing subject 082 82/105...Ok\n",
      "Processing subject 083 83/105...Ok\n",
      "Processing subject 084 84/105...Ok\n",
      "Processing subject 085 85/105...Ok\n",
      "Processing subject 086 86/105...Ok\n",
      "Processing subject 087 87/105...Ok\n",
      "Processing subject 089 88/105...Ok\n",
      "Processing subject 090 89/105...Ok\n",
      "Processing subject 091 90/105...Ok\n",
      "Processing subject 093 91/105...Ok\n",
      "Processing subject 094 92/105...Ok\n",
      "Processing subject 095 93/105...Ok\n",
      "Processing subject 096 94/105...Ok\n",
      "Processing subject 097 95/105...Ok\n",
      "Processing subject 098 96/105...Ok\n",
      "Processing subject 099 97/105...Ok\n",
      "Processing subject 101 98/105...Ok\n",
      "Processing subject 102 99/105...Ok\n",
      "Processing subject 103 100/105...Ok\n",
      "Processing subject 105 101/105...Ok\n",
      "Processing subject 106 102/105...Ok\n",
      "Processing subject 107 103/105...Ok\n",
      "Processing subject 108 104/105...Ok\n",
      "Processing subject 109 105/105...Ok\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'processedPath' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e919a0884e67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessedPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processedPath' is not defined"
     ]
    }
   ],
   "source": [
    "X, y, subs = get_data('./Dataset/', ds=2)\n",
    "print(X.shape, y.shape, subs.shape)"
   ]
  },
  {
   "source": [
    "Once the data is loaded and preprocessed, it must be saved in a folder using the names `samples.npy`, `labels.npy` and `subs.npy`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedPath = 'ds2/'\n",
    "\n",
    "try:\n",
    "    os.mkdir(processedPath)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "np.save(processedPath+'samples.npy', X)\n",
    "np.save(processedPath+'labels.npy', y)\n",
    "np.save(processedPath+'subs.npy', subs)"
   ]
  },
  {
   "source": [
    "## Global model training\n",
    "\n",
    "The validation method used here is 5-fold crossvalidation across subjects. This means that for each global 'model' 5 diferent models will be trianed, using an iterating fifth of the subjects as the valdiation set.\n",
    "\n",
    "The model architecture is the diplayed in the following picture, which is further detailed in the table bellow. In short it is based on the EEGNet, a Convolutional Neural Network that showed its versatility when EEG recordings must be processed. The only changes are:\n",
    "\n",
    "- The substitution of the ELU activation function for the LeakyReLU which is cheaper to implement in hardware.\n",
    "\n",
    "- The remove of the Dropout and BatchNorm layers.\n",
    "\n",
    "<img src='img/EEGNet.png' />\n",
    "\n",
    "|     Layer          |     #   filters    |     Padding    |     Kernel           |     #   parms          |     Activation       |     Output   shape           |\n",
    "|--------------------|--------------------|----------------|----------------------|------------------------|----------------------|------------------------------|\n",
    "|     Input          |     -              |     -          |     -                |     -                  |     -                |     (Nchan,   fs·T/ds, 1)    |\n",
    "|     Conv2D         |     4              |     same       |     (1,   fs/2ds)    |     2fs/ds             |     LReLU   (0.6)    |     (Nchan,   fs·T/ds, 4)    |\n",
    "|     DepthConv2D    |     2·4            |     valid      |     (Nchan,   1)     |     8Nchan             |     LReLU   (0.5)    |     (1, fs·T/ds,   8)        |\n",
    "|     AvgPool2D      |     -              |     valid      |     (1,   6/ds)      |     -                  |     -                |     (1, fs·T/6,   8)         |\n",
    "|     SepConv2D      |     8              |     same       |     (1,   16)        |     192                |     LReLU   (0.4)    |     (1, fs·T/6,   8)         |\n",
    "|     AvgPool2D      |     -              |     valid      |     (1,   8)         |     -                  |     -                |     (1, fs·T/48,   8)        |\n",
    "|     Flatten        |     -              |     -          |     -                |     -                  |     -                |     fs·T/6                   |\n",
    "|     Dense          |     Nclasses       |     -          |     -                |     Nclasses fs·T/6    |     Softmax          |     Nclasses                 |\n",
    "\n",
    "To automate the process of noramlizing the data, choosing the correct subjects of the valdiation set and training the models with the fine tunned hyperparamters, "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}