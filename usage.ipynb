{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIBCI-QCNNs: Usage\n",
    "\n",
    "This notebook contains the code to test the EEGNet-based model implemented in the Red Pitaya's PL.\n",
    "\n",
    "In this notebook only one fold is validated. The fold's parameters and its validation dataset must be included, so the following tree its expected to be in the same root as this notebook:\n",
    "```\n",
    "global_model/\n",
    "├── npyparams/\n",
    "│   ├── conv2d_w.npy\n",
    "│   ├── dense_b.npy\n",
    "│   ├── dense_w.npy\n",
    "│   ├── depthconv2d_w.npy\n",
    "│   ├── sepdepthconv2d_w.npy\n",
    "│   └── seppointconv2d_w.npy\n",
    "└── validationDS/\n",
    "    ├── X_samples/\n",
    "    │   ├── X_0.npy\n",
    "    │   ├── X_1.npy\n",
    "    │   ├── ·······\n",
    "    │   └── X_3527.npy\n",
    "    ├── y_hls_16_8.txt\n",
    "    ├── y_pred.npy\n",
    "    └── y_true.npy\n",
    "\n",
    "```\n",
    "\n",
    "Make sure to meet the following dependencies for the ARM Cortex-A9 architecture, `armv7l`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mmap\n",
    "import os\n",
    "import struct\n",
    "from numpy import clip\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import progressbar\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to some error when using the `accuracy_socre` function of `scikit-learn`, here is an own-implementation of it using `numpy`. It will serve to compute the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \n",
    "    if len(y_true.shape) != 1 or len(y_pred.shape) != 1:\n",
    "        raise ValueError('Both y_true and y_pred must be 1-dimensional.')\n",
    "        \n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError('y_true and y_pred must be equally sized.')\n",
    "    \n",
    "    return (y_true == y_pred).sum()/len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs and outputs of the model can be accessed through the AXI-reserved memory registers, starting from the `0x40000000`. To access these registers from Python, the memory-mapped file `/dev/mem` can be used.\n",
    "\n",
    "In the next cell a driver class named `overlay` is defined. In its `__init()__` function the bitstream is loaded and the `/dev/mem` is opened with an offset of `0x40000000`, the same offset present in the addresses appearing in the `x<name-of-the-HLS-project>_hw.h` file inside of the `<name-of-the-HLS-project>/solutionX/impl/ip/drivers/<top-func-name>_vX_0/src/` HLS project directory. Then functions there are the definitions to read and write a 16 bits fixed-point value and their generalizaiton for N-dimentional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class overlay():\n",
    "    \n",
    "    def __init__(self, bitfile: str) -> None:\n",
    "        \"\"\"Sets the bitfile in the FPGA and opens the `/dev/mem` file to acces the AXI interface.\n",
    "        \"\"\"\n",
    "        \n",
    "        if(bitfile[-4:] != '.bit'):\n",
    "            raise ValueError('The overlay must be inititalized with a .bit file.')\n",
    "        os.system('cat {} > /dev/xdevcfg'.format(bitfile))\n",
    "        \n",
    "        fd = os.open('/dev/mem', os.O_RDWR)\n",
    "        self.m = mmap.mmap(fileno=fd, length=0x1100f+1, offset=0x40000000)\n",
    "    \n",
    "    def writefp16(self, addr: int, value: float, BitsInt: int = 8) -> None:\n",
    "        \"\"\"Writes a real number as a fixed-point 16-X (16-8 as default) in the addr address.\n",
    "        \"\"\"\n",
    "        self.m[addr:addr+2] = struct.pack('<h', int(clip(round(value*(2**(16-BitsInt))), -2**15, 2**15-1)))\n",
    "    \n",
    "    def readfp16(self, addr: int, BitsInt: int = 8) -> float:\n",
    "        \"\"\"Reads a real number as fixed-point 16-X (16-8 as default) in the addr address.\n",
    "        \"\"\"\n",
    "        return struct.unpack('<h', self.m[addr:addr+2])[0]*2**-(16-BitsInt)\n",
    "    \n",
    "    def write_array(self, initial_addr: int, array: np.ndarray) -> None:\n",
    "        addr = initial_addr\n",
    "        for i in range(int(len(array)/2)):\n",
    "            try:\n",
    "                self.writefp16(addr, array[2*i])\n",
    "                self.writefp16(addr+2, array[2*i+1])\n",
    "                addr += 4\n",
    "            except:\n",
    "                print(i)\n",
    "                print(array[2*i], array[2*i+1])\n",
    "                raise\n",
    "    \n",
    "    def read_array(self, initial_addr: int, array_len: int) -> np.ndarray:\n",
    "        addr = initial_addr\n",
    "        array = np.empty(array_len)\n",
    "        for i in range(int(array_len/2)):\n",
    "            array[2*i] = self.readfp16(addr)\n",
    "            array[2*i+1] = self.readfp16(addr+2)\n",
    "            addr += 4\n",
    "        \n",
    "        return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, the bitstream is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIBCI_QCNN = overlay('MIBCI-QCNNs.bit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the parameters' names and their AXI addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npyParamsNames = ['conv2d_w', 'depthconv2d_w', 'sepdepthconv2d_w', 'seppointconv2d_w', 'dense_w', 'dense_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_addrs = [0x10000, 0x10400, 0x10900, 0x10a00, 0x10c00, 0x11000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model parameters are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param in enumerate(npyParamsNames):\n",
    "    MIBCI_QCNN.write_array(params_addrs[i], np.load('global_model/npyparams/{}.npy'.format(param)).flatten())\n",
    "\n",
    "MIBCI_QCNN.writefp16(0x10200, 0.6)\n",
    "MIBCI_QCNN.writefp16(0x10800, 0.5)\n",
    "MIBCI_QCNN.writefp16(0x10a80, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the FPGA is ready to be tested in all the validaiton set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nsamples = len(os.listdir('global_model/validationDS/X_samples/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (3528 of 3528) |####################| Elapsed Time: 1:26:58 Time:  1:26:58\n"
     ]
    }
   ],
   "source": [
    "y_fpga = np.empty(Nsamples)\n",
    "for i in progressbar.progressbar(range(Nsamples)):\n",
    "    X = np.load('global_model/validationDS/X_samples/X_{}.npy'.format(i))\n",
    "    MIBCI_QCNN.write_array(0x08000, X.flatten())\n",
    "    #time.sleep(0.07)\n",
    "    y_fpga[i] = np.argmax(MIBCI_QCNN.read_array(0x11008, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hls = np.loadtxt('global_model/validationDS/y_hls_16_8.txt', usecols=[0])[:Nsamples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = np.load('global_model/validationDS/y_true.npy')[:Nsamples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.load('global_model/validationDS/y_pred.npy')[:Nsamples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the valdiaiton accuracy for each implementation is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  --------\n",
      "Keras  0.680839\n",
      "HLS    0.681122\n",
      "FPGA   0.670635\n",
      "-----  --------\n",
      "Nsamples: 3528\n"
     ]
    }
   ],
   "source": [
    "table = [['Keras', accuracy_score(y_true, y_pred)], ['HLS', accuracy_score(y_true, y_hls)], ['FPGA',  accuracy_score(y_true, y_fpga)]]\n",
    "\n",
    "print(tabulate(table))\n",
    "print('Nsamples: {}'.format(Nsamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "319c24ade14b7873a3f936c1569cf8c1853592b8350107cb8f60c9b2a2771b37"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
