{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MIBCI-QCNNs: Usage\n",
    "\n",
    "This notebook contains the code to test the EEGNet-based model implemented in the Red Pitaya's PL.\n",
    "\n",
    "The entire model must be uploaded to the Red Pitaya, including the `createnpys`-generated files. The tree must be:\n",
    "```\n",
    "global_model/\n",
    "├── fold_0\n",
    "│   ├── npyparams/\n",
    "│   │   ├── conv2d_w.npy\n",
    "│   │   ├── dense_b.npy\n",
    "│   │   ├── dense_w.npy\n",
    "│   │   ├── depthconv2d_w.npy\n",
    "│   │   ├── sepdepthconv2d_w.npy\n",
    "│   │   └── seppointconv2d_w.npy\n",
    "│   └── validationDS/\n",
    "│       ├── X_samples/\n",
    "│       │   ├── X_0.npy\n",
    "│       │   ├── X_1.npy\n",
    "│       │   ├── ·······\n",
    "│       │   └── X_3527.npy\n",
    "│       ├── y_hls_16_8.txt\n",
    "│       ├── y_pred.npy\n",
    "│       └── y_true.npy\n",
    "├── fold_1\n",
    "│   ├── npyparams/\n",
    "│   │   └── ·······\n",
    "│   └── validationDS/\n",
    "│       └── ·······\n",
    "├── fold_2\n",
    "│   └── ·······\n",
    "├── fold_3\n",
    "│   └── ·······\n",
    "└── fold_4\n",
    "    └── ·······\n",
    "```\n",
    "\n",
    "Make sure to meet the following dependencies for the ARM Cortex-A9 architecture, `armv7l`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mmap\n",
    "import os\n",
    "import struct\n",
    "from numpy import clip\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import tqdm\n",
    "import time\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to some error when using the `accuracy_socre` function of `scikit-learn`, here is an own-implementation of it using `numpy`. It will serve to compute the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \n",
    "    if len(y_true.shape) != 1 or len(y_pred.shape) != 1:\n",
    "        raise ValueError('Both y_true and y_pred must be 1-dimensional.')\n",
    "        \n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError('y_true and y_pred must be equally sized.')\n",
    "    \n",
    "    return (y_true == y_pred).sum()/len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs and outputs of the model can be accessed through the AXI-reserved memory registers, starting from the `0x40000000`. To access these registers from Python, the memory-mapped file `/dev/mem` can be used.\n",
    "\n",
    "In the next cell a driver class named `overlay` is defined. In its `__init()__` function the bitstream is loaded and the `/dev/mem` is opened with an offset of `0x40000000`, the same offset present in the addresses appearing in the `x<name-of-the-HLS-project>_hw.h` file inside of the `<name-of-the-HLS-project>/solutionX/impl/ip/drivers/<top-func-name>_vX_0/src/` HLS project directory. Then functions there are the definitions to read and write a 16 bits fixed-point value and their generalizaiton for N-dimentional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class overlay():\n",
    "    \n",
    "    def __init__(self, bitfile: str) -> None:\n",
    "        \"\"\"Sets the bitfile in the FPGA and opens the `/dev/mem` file to acces the AXI interface.\n",
    "        \"\"\"\n",
    "        \n",
    "        if(bitfile[-4:] != '.bit'):\n",
    "            raise ValueError('The overlay must be inititalized with a .bit file.')\n",
    "        os.system('cat {} > /dev/xdevcfg'.format(bitfile))\n",
    "        \n",
    "        fd = os.open('/dev/mem', os.O_RDWR)\n",
    "        self.m = mmap.mmap(fileno=fd, length=0x1100f+1, offset=0x40000000)\n",
    "    \n",
    "    def writefp16(self, addr: int, value: float, BitsInt: int = 8) -> None:\n",
    "        \"\"\"Writes a real number as a fixed-point 16-X (16-8 as default) in the addr address.\n",
    "        \"\"\"\n",
    "        self.m[addr:addr+2] = struct.pack('<h', int(clip(round(value*(2**(16-BitsInt))), -2**15, 2**15-1)))\n",
    "    \n",
    "    def readfp16(self, addr: int, BitsInt: int = 8) -> float:\n",
    "        \"\"\"Reads a real number as fixed-point 16-X (16-8 as default) in the addr address.\n",
    "        \"\"\"\n",
    "        return struct.unpack('<h', self.m[addr:addr+2])[0]*2**-(16-BitsInt)\n",
    "    \n",
    "    def write_array(self, initial_addr: int, array: np.ndarray) -> None:\n",
    "        addr = initial_addr\n",
    "        for i in range(int(len(array)/2)):\n",
    "            try:\n",
    "                self.writefp16(addr, array[2*i])\n",
    "                self.writefp16(addr+2, array[2*i+1])\n",
    "                addr += 4\n",
    "            except:\n",
    "                print(i)\n",
    "                print(array[2*i], array[2*i+1])\n",
    "                raise\n",
    "    \n",
    "    def read_array(self, initial_addr: int, array_len: int) -> np.ndarray:\n",
    "        addr = initial_addr\n",
    "        array = np.empty(array_len)\n",
    "        for i in range(int(array_len/2)):\n",
    "            array[2*i] = self.readfp16(addr)\n",
    "            array[2*i+1] = self.readfp16(addr+2)\n",
    "            addr += 4\n",
    "        \n",
    "        return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, the bitstream is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIBCI_QCNN = overlay('MIBCI-QCNNs.bit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the parameters' names and their AXI addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npyParamsNames = ['conv2d_w', 'depthconv2d_w', 'sepdepthconv2d_w', 'seppointconv2d_w', 'dense_w', 'dense_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_addrs = [0x10000, 0x10400, 0x10900, 0x10a00, 0x10c00, 0x11000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model parameters are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_root = 'global_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c6635a623146aa9eb906816c7c3c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cf1060dc01450197cc85c74e9a54a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5053419bb23f4f8fbd823883c792894f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4ec4ffe91b4a4b8e61783e0dd0a140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15f196efbbc448b835dd32972caeaf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c7e5cb98ac4c03b95aa3d651492931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold       Keras       HLS      FPGA\n",
      "------  --------  --------  --------\n",
      "0       0.680839  0.681122  0.665816\n",
      "1       0.651077  0.646825  0.610261\n",
      "2       0.693311  0.694728  0.65051\n",
      "3       0.633503  0.630669  0.606293\n",
      "4       0.619331  0.619048  0.609977\n",
      "Mean    0.655612  0.654478  0.628571\n"
     ]
    }
   ],
   "source": [
    "table = [['Fold', 'Keras', 'HLS', 'FPGA']]\n",
    "\n",
    "for fold in tqdm.tqdm_notebook(range(5), desc='Folds'):\n",
    "    row_tmp = [fold]\n",
    "    \n",
    "    for i, param in enumerate(npyParamsNames):\n",
    "        MIBCI_QCNN.write_array(params_addrs[i], np.load('{}/fold_{}/npyparams/{}.npy'.format(model_root, fold, param)).flatten())\n",
    "\n",
    "    MIBCI_QCNN.writefp16(0x10200, 0.6)\n",
    "    MIBCI_QCNN.writefp16(0x10800, 0.5)\n",
    "    MIBCI_QCNN.writefp16(0x10a80, 0.4)\n",
    "\n",
    "    Nsamples = len(os.listdir('{}/fold_{}/validationDS/X_samples/'.format(model_root, fold)))\n",
    "    y_fpga = np.empty(Nsamples)\n",
    "    \n",
    "    for i in tqdm.tqdm_notebook(range(Nsamples), leave=False, desc='Samples'):\n",
    "        X = np.load('{}/fold_{}/validationDS/X_samples/X_{}.npy'.format(model_root, fold, i))\n",
    "        MIBCI_QCNN.write_array(0x08000, X.flatten())\n",
    "        #time.sleep(0.07)\n",
    "        y_fpga[i] = np.argmax(MIBCI_QCNN.read_array(0x11008, 4))\n",
    "    \n",
    "    y_hls = np.loadtxt('{}/fold_{}/validationDS/y_hls_16_8.txt'.format(model_root, fold), usecols=[0])[:Nsamples]\n",
    "    y_true = np.load('{}/fold_{}/validationDS/y_true.npy'.format(model_root, fold))[:Nsamples]\n",
    "    y_pred = np.load('{}/fold_{}/validationDS/y_pred.npy'.format(model_root, fold))[:Nsamples]\n",
    "    \n",
    "    row_tmp.append(accuracy_score(y_true, y_pred))\n",
    "    row_tmp.append(accuracy_score(y_true, y_hls))\n",
    "    row_tmp.append(accuracy_score(y_true, y_fpga))\n",
    "    \n",
    "    table.append(row_tmp)\n",
    "\n",
    "row_tmp = ['Mean']\n",
    "for i in range(1,4):\n",
    "    tmp=0\n",
    "    for j in range(1,6):\n",
    "        tmp += table[j][i]\n",
    "    row_tmp.append(tmp/5)\n",
    "table.append(row_tmp)\n",
    "    \n",
    "print(tabulate(table, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "319c24ade14b7873a3f936c1569cf8c1853592b8350107cb8f60c9b2a2771b37"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
